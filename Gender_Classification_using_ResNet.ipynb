{
  "cells": [
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'gender-classification-dataset:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F446365%2F844929%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240217%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240217T133522Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D361bdbc6315d829610576d74731efb0ce37bddbcd1036c07afa44a77ce9e163dd8768b0bd5bedf5354e3a179faa9bd117a19b72e3adf36602866f03584fb02b6ae964804e663adf749ac299103ed5592ff69b23b8a25426585c196099d9d1db8f9510b9c1f5e8107a6c9851031d26e111da47d95fd742a94b69fec942360e26e92fc0bcb02c50bb88f11c9bf4f0cbcb7a30a2b1ffb5f7cd4962fb663627f962921a496dc1f666d5f462d75029d176c45842554ef00da35896e9799422fe7180ff6b8f503f9d37249176af16e6d16d352fbcbb559462e05356c12ab49405ebe0c905079b06b7987a6c66f7c625ec0f07392fafe0f8edd835eab53c6749a0548ef,resnet50:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F504915%2F936546%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240217%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240217T133522Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D0a69c62f2ec7b863b9382edbb17ed6a59290827def295292aa4d2d1b28fa371d209859b85dfd4acd15517bd3328de490db9a132db0a01a2aa9d096b914192d83848f46a412c1585c75097f2741d2580d42a8bcbf9442410bc1bc4ae08b6e5365cfaeea18c84741a41d3415240507a424b7cddb7282357e3f04551af92476c0e67112c2df61fcfef0d7ccc69461387425243326a8cab454efa38f1da11e68138007a7c8c6477c5f1849854816db25bd7feaab20781a7cc2ae74d89c38c966a73e2647838b05586cebb997cd31e53cab14f765a31ff3cb06281cdc3b1ca6e9c5d5516f6a69eaa64432984604c7f480d5a39d0b30f5bea88f00c21f9ec6155d174f'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "Pi7YhntuR1HL",
        "outputId": "cefafb22-3117-4b71-d668-36d0470a83c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading gender-classification-dataset, 282512091 bytes compressed\n",
            "[==================================================] 282512091 bytes downloaded\n",
            "Downloaded and uncompressed: gender-classification-dataset\n",
            "Downloading resnet50, 87541466 bytes compressed\n",
            "[==================================================] 87541466 bytes downloaded\n",
            "Downloaded and uncompressed: resnet50\n",
            "Data source import complete.\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "metadata": {
        "trusted": false,
        "id": "KUty708ER1HM"
      },
      "cell_type": "code",
      "source": [
        "# do the necessary imports\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import cv2\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "from keras.layers import *\n",
        "from keras.models import *\n",
        "import keras\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false,
        "id": "S4bVCQT0R1HN"
      },
      "cell_type": "code",
      "source": [
        "# Hyper - parameters\n",
        "\n",
        "epochs = 100\n",
        "lr = 1e-3\n",
        "batch_size = 64\n",
        "#img_dims = (96,96,3)\n",
        "\n",
        "data = []\n",
        "labels = []"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false,
        "id": "fCPYPySuR1HN"
      },
      "cell_type": "code",
      "source": [
        "size = 224"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false,
        "id": "iEPUIidVR1HN"
      },
      "cell_type": "code",
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false,
        "id": "R71suPE2R1HN"
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PFlOF05-R1HN"
      },
      "cell_type": "markdown",
      "source": [
        "**RESNET 50**"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "7B-IVXqpR1HO"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, GlobalAveragePooling2D, BatchNormalization\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "\n",
        "resnet_weights_path = '../input/resnet50/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "M2d20sUUR1HO"
      },
      "cell_type": "code",
      "source": [
        "# CALLBACKS\n",
        "\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "es = EarlyStopping(patience=5, monitor = 'val_accuracy')\n",
        "rlp = ReduceLROnPlateau(patience=5, monitor = 'val_accuracy')\n",
        "\n",
        "callbacks = [es, rlp]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "yCqHZQvbR1HO",
        "outputId": "58b85997-cb6b-4686-e45a-7a2b1b997e92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        }
      },
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(horizontal_flip=True,\n",
        "                                   width_shift_range = 0.4,\n",
        "                                   height_shift_range = 0.4,\n",
        "                                   zoom_range=0.3,\n",
        "                                   rotation_range=20,\n",
        "                                   rescale = 1./255\n",
        "                                   )\n",
        "\n",
        "test_gen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "image_size = 224\n",
        "batch_size = 64\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        '../input/gender-classification-dataset/Training',\n",
        "        target_size=(image_size, image_size),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='binary')\n",
        "\n",
        "validation_generator = test_gen.flow_from_directory(\n",
        "    '../input/gender-classification-dataset/Validation',\n",
        "    target_size = (image_size, image_size),\n",
        "    batch_size = batch_size,\n",
        "    class_mode = 'binary'\n",
        ")\n",
        "\n",
        "num_classes = len(train_generator.class_indices)\n",
        "print('Numer of classes:' ,num_classes)\n",
        "print('Class labels: ', train_generator.class_indices)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale = 1./255,\n",
        "    shear_range = 0.2,\n",
        "    zoom_range = 0.2,\n",
        "    horizontal_flip = True\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_path,\n",
        "    target_size = (size, size),\n",
        "    batch_size = batch_size,\n",
        "    class_mode = 'binary'\n",
        ")\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    valid_path,\n",
        "    target_size = (size, size),\n",
        "    batch_size = batch_size,\n",
        "    class_mode = 'binary'\n",
        ")\n",
        "\n",
        "\"\"\""
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 47009 images belonging to 2 classes.\n",
            "Found 11649 images belonging to 2 classes.\n",
            "Numer of classes: 2\n",
            "Class labels:  {'female': 0, 'male': 1}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\ntrain_datagen = ImageDataGenerator(\\n    rescale = 1./255, \\n    shear_range = 0.2, \\n    zoom_range = 0.2,\\n    horizontal_flip = True\\n)\\n\\ntest_datagen = ImageDataGenerator(rescale = 1./255)\\n\\ntrain_generator = train_datagen.flow_from_directory(\\n    train_path, \\n    target_size = (size, size),\\n    batch_size = batch_size,\\n    class_mode = 'binary'\\n)\\n\\nvalidation_generator = test_datagen.flow_from_directory(\\n    valid_path,\\n    target_size = (size, size),\\n    batch_size = batch_size, \\n    class_mode = 'binary'\\n)\\n\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "fHLcQv4jR1HO",
        "outputId": "5bc68be9-22a6-4b59-dc17-301336a85ca9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(ResNet50(include_top=False, pooling='avg', weights='imagenet'))\n",
        "model.add(Flatten())\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(2048, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.layers[0].trainable = False"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94765736/94765736 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "guxkAIGiR1HO",
        "outputId": "fc4f944d-eb2f-4235-ab01-ec0db56114a5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " resnet50 (Functional)       (None, 2048)              23587712  \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2048)              0         \n",
            "                                                                 \n",
            " batch_normalization (Batch  (None, 2048)              8192      \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2048)              4196352   \n",
            "                                                                 \n",
            " batch_normalization_1 (Bat  (None, 2048)              8192      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1024)              2098176   \n",
            "                                                                 \n",
            " batch_normalization_2 (Bat  (None, 1024)              4096      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 1025      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 29903745 (114.07 MB)\n",
            "Trainable params: 6305793 (24.05 MB)\n",
            "Non-trainable params: 23597952 (90.02 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "69Z-b-A6R1HO"
      },
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "Dge63wudR1HP",
        "outputId": "b5d70c23-bdd9-4069-f836-6de8397f3982",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "model.fit_generator(train_generator, steps_per_epoch = int(47000/64) + 1  , epochs = 30, validation_data = validation_generator, callbacks = callbacks)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-99356035681d>:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  model.fit_generator(train_generator, steps_per_epoch = int(47000/64) + 1  , epochs = 30, validation_data = validation_generator, callbacks = callbacks)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "  8/735 [..............................] - ETA: 2:39:27 - loss: 2.3650 - accuracy: 0.5059"
          ]
        }
      ]
    },
    {
      "metadata": {
        "trusted": false,
        "id": "-yBgjmwWR1HP"
      },
      "cell_type": "code",
      "source": [
        "model.save('model3.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sA0RtOUsR1HP"
      },
      "cell_type": "markdown",
      "source": [
        "w/o pretrained weights"
      ]
    },
    {
      "metadata": {
        "trusted": false,
        "id": "yFNdo_BRR1HP"
      },
      "cell_type": "code",
      "source": [
        "model2 = Sequential()\n",
        "\n",
        "model2.add(ResNet50(include_top=False, pooling='avg', weights=None))\n",
        "model2.add(Flatten())\n",
        "model2.add(BatchNormalization())\n",
        "model2.add(Dense(2048, activation='relu'))\n",
        "model2.add(BatchNormalization())\n",
        "model2.add(Dense(1024, activation='relu'))\n",
        "model2.add(BatchNormalization())\n",
        "model2.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model2.layers[0].trainable = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false,
        "id": "uZBIclTnR1HP"
      },
      "cell_type": "code",
      "source": [
        "model2.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false,
        "id": "XeS4asPtR1HP"
      },
      "cell_type": "code",
      "source": [
        "model2.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false,
        "id": "t1PLB_L8R1HP"
      },
      "cell_type": "code",
      "source": [
        "model2.fit_generator(train_generator, steps_per_epoch = int(47000/64) + 1  , epochs = 50, validation_data = validation_generator, callbacks = callbacks)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "ZkRAXsiqR1HP"
      },
      "cell_type": "code",
      "source": [
        "model2.save('model4.h5')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "Gender Classification using ResNet",
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}